{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Light Beads Microscopy Demo Pipeline \n",
    "\n",
    "## Pipeline Steps\n",
    "\n",
    "### Pre-Processing:\n",
    "- Extract ScanImage metadata\n",
    "- Correct Bi-Directional Offset for each ROI\n",
    "- Calculates and corrects the MROI seams (IN PROGRESS)\n",
    "### Motion Correction\n",
    "\n",
    "- Apply the nonrigid motion correction (NoRMCorre) algorithm for motion correction.\n",
    "- View pre/most correction movie\n",
    "- Use quality metrics to evaluate registration quality\n",
    "\n",
    "### Segmentation\n",
    "\n",
    "- Apply the constrained nonnegative matrix factorization (CNMF) source separation algorithm to extract initial estimates of neuronal spatial footprints and calcium traces.\n",
    "- Apply quality control metrics to evaluate the initial estimates, and narrow down to the final set of estimates.\n",
    "\n"
   ],
   "id": "5557172c61dea2ef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Imports and general setup",
   "id": "9205103d113948d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "\n",
    "sys.path.append('../util/')  # TODO: Take this out when we upload to pypi\n",
    "sys.path.append('../exclude/')  # TODO: Take this out when we upload to pypi\n",
    "import scanreader\n",
    "import util\n",
    "from scan import fix_scan_phase, return_scan_offset\n",
    "\n",
    "import bokeh.plotting as bpl\n",
    "import holoviews as hv\n",
    "from IPython import get_ipython\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except():\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "        get_ipython().run_line_magic('autoreload', '2')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "import caiman as cm\n",
    "\n",
    "bpl.output_notebook()\n",
    "hv.notebook_extension('bokeh')"
   ],
   "id": "3b639e0144677275"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Set up a few helper functions for plotting, logging and setting up our environment",
   "id": "b84331f5bb7a630e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_frame(img, title='', savepath='', **kwargs):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(img, **kwargs)\n",
    "    fig.suptitle(f'{title}')\n",
    "    fig.tight_layout()\n",
    "    if savepath:\n",
    "        plt.savefig(savepath, **kwargs)\n",
    "    plt.show()\n",
    "\n",
    "# set up logging\n",
    "logging.basicConfig(format=\"{asctime} - {levelname} - [{filename} {funcName}() {lineno}] - pid {process} - {message}\",\n",
    "                    filename=None, \n",
    "                    level=logging.WARNING, style=\"{\") # this shows you just errors that can harm your program\n",
    "                    # level=logging.DEBUG, style=\"{\") # this shows you general information that developers use to trakc their program \n",
    "                    # (be careful when playing movies, there will be a lot of debug messages)\n",
    "\n",
    "# set env variables \n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\""
   ],
   "id": "5514c90622ebeb6b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Extract data using scanreader, joining contiguous ROI's, and plot our mean image",
   "id": "64e99a6a3339cbb8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "datapath = Path('/data2/fpo/data/')                 # string pointing to directory containing your data\n",
    "tiffs = [x for x in datapath.glob('*.tif')]         # this accumulates a list of every filepath which contains a .tif file\n",
    "\n",
    "reader = scanreader.read_scan(str(tiffs[0]), join_contiguous=False)\n",
    "print(f'Number of ROIs: {len(reader)}')"
   ],
   "id": "f0c493fd53b8b4c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Scan Phase Correction\n",
    "\n",
    "Methods:\n",
    "1) Linear interpolation\n",
    "2) Phase - cross correlation"
   ],
   "id": "5454f9e10527b3d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "roi_1 = reader[0]\n",
    "slice_plane = roi_1[:,:,5,:]\n",
    "phase_angle =  util.compute_raster_phase(slice_plane[:,:, 400], reader.temporal_fill_fraction)\n",
    "corrected_li = util.correct_raster(slice_plane, phase_angle, reader.temporal_fill_fraction)"
   ],
   "id": "685e64bb3180e04b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "from bokeh.models import Range1d\n",
    "\n",
    "def bounds_hook(plot, elem, xbounds=None, ybounds=None):\n",
    "    x_range = plot.handles['plot'].x_range\n",
    "    y_range = plot.handles['plot'].y_range\n",
    "    if xbounds is not None:\n",
    "        x_range.bounds = xbounds\n",
    "    else:\n",
    "        x_range.bounds = x_range.start, x_range.end \n",
    "    if ybounds is not None:\n",
    "        y_range.bounds = ybounds\n",
    "    else:\n",
    "        y_range.bounds = y_range.start, y_range.end \n",
    "\n",
    "aspect_ratio = slice_plane.shape[1] / slice_plane.shape[0]\n",
    "\n",
    "range_x = Range1d(start=0, end=slice_plane.shape[1])\n",
    "range_y = Range1d(start=0, end=slice_plane.shape[0])\n",
    "\n",
    "plot_width = 600\n",
    "plot_height = int(plot_width / aspect_ratio)\n",
    "\n",
    "image1 = hv.Image(slice_plane[:,:,400]).opts(\n",
    "    width=plot_width,\n",
    "    height=plot_height,\n",
    "    title=\"Original Image\",\n",
    "    tools=['hover', 'pan', 'wheel_zoom'],\n",
    "    cmap='gray', \n",
    "    hooks=[bounds_hook])\n",
    "\n",
    "image2 = hv.Image(corrected_li[:,:,400]).opts(\n",
    "    width=plot_width,\n",
    "    height=plot_height,\n",
    "    title=\"Corrected Image\",\n",
    "    tools=['hover', 'pan', 'wheel_zoom'],\n",
    "    cmap='gray',\n",
    "    hooks=[bounds_hook], \n",
    "    )\n",
    "\n",
    "# Combine the images into a layout\n",
    "layout = image1 + image2\n",
    "\n",
    "# Display the layout\n",
    "# hv.save(layout, '../docs/img/comparison.html')\n",
    "bpl.show(hv.render(layout))"
   ],
   "id": "338b4e7a81a670d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ph = return_scan_offset(roi_1, 1)\n",
    "corrected_pc = fix_scan_phase(roi_1, ph, 1)"
   ],
   "id": "13ea947e68d30f8b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "image1 = hv.Image(roi_1[:,:,4,100]).opts(\n",
    "    width=plot_width,\n",
    "    height=plot_height,\n",
    "    title=\"Original Image\",\n",
    "    tools=['hover', 'pan', 'wheel_zoom'],\n",
    "    cmap='gray', \n",
    "    hooks=[bounds_hook])\n",
    "\n",
    "image2 = hv.Image(corrected_pc[:,:,4,100]).opts(\n",
    "    width=plot_width,\n",
    "    height=plot_height,\n",
    "    title=\"Corrected Image\",\n",
    "    tools=['hover', 'pan', 'wheel_zoom'],\n",
    "    cmap='gray',\n",
    "    hooks=[bounds_hook], \n",
    "    )\n",
    "\n",
    "layout = image1 + image2\n",
    "\n",
    "# Display the layout\n",
    "# hv.save(layout, '../docs/img/comparison.html')\n",
    "bpl.show(hv.render(layout))"
   ],
   "id": "a2d3c87f7a3c48a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Join Contiguious ROI's\n",
    "\n",
    "Setting `join_contiguous=True` will combine ROI's with the following constraints:\n",
    "1) Must be the same size/shape\n",
    "2) Must be located in the same scanning depth\n",
    "3) Must be located in the same slice\n",
    "- ROI can be directly left, right, above or below the adjacent ROI's"
   ],
   "id": "e3ee2dc1544aceff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create another reader, without joining contiguous fields\n",
    "contig = scanreader.read_scan(str(tiffs[0]), join_contiguous=True) \n",
    "num_roi=len(contig)        # we now have a single ROI due to the merging \n",
    "data = contig[0]\n",
    "fig, ax = plt.subplots(ncols=2)\n",
    "ax[0].imshow(data[:,:, 5, 400])\n",
    "ax[1].imshow(data[100:160,125:165,5,400])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "af70c297a131dcaa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "do_stats = False\n",
    "if do_stats:\n",
    "    result_dict = {}\n",
    "    for field_id, data in enumerate(reader_cont):\n",
    "        print(field_id)\n",
    "        for channel in range(reader_cont.num_channels):\n",
    "            key_str = f\"{field_id}_{channel}\"\n",
    "            results = util.performance.map_frames(\n",
    "                util.performance.parallel_quality_metrics,\n",
    "                reader_cont,\n",
    "                field_id=field_id,\n",
    "                channel=channel,\n",
    "            )\n",
    "\n",
    "            # Reduce\n",
    "            mean_intensities = np.zeros(reader_cont.num_frames)\n",
    "            contrasts = np.zeros(reader_cont.num_frames)\n",
    "            for frames, chunk_mis, chunk_contrasts, _ in results:\n",
    "                mean_intensities[frames] = chunk_mis\n",
    "                contrasts[frames] = chunk_contrasts\n",
    "\n",
    "            result_dict[key_str] = {\n",
    "                \"mean_intensities\": mean_intensities,\n",
    "                \"contrasts\": contrasts,\n",
    "            }"
   ],
   "id": "43101d1eaa361270"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Motion Correction: CaImAn - NORMCorre",
   "id": "556a687d5fe23ee1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "movie = cm.movie(slice, start_time=2, fr=reader.fps)\n",
    "downsampling_ratio = 0.2  # subsample 5x\n",
    "movie = movie.resize(fz=downsampling_ratio)\n",
    "# movie.play(gain=1.3, backend='embed_opencv')"
   ],
   "id": "68d09e14938de104"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Create a couple of summary images of the movie, including:\n",
    "- maximum projection (the maximum value of each pixel) \n",
    "- correlation image (how correlated each pixel is with its neighbors)\n",
    "\n",
    "If a pixel comes from an active neural component it will tend to be highly correlated with its neighbors."
   ],
   "id": "c8f76fdb01de841c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "max_projection_orig = np.max(movie, axis=0)\n",
    "correlation_image_orig = cm.local_correlations(movie, swap_dim=False)\n",
    "correlation_image_orig[np.isnan(correlation_image_orig)] = 0 # get rid of NaNs, if they exist"
   ],
   "id": "14415bc6ee9d6bed"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
