{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d067b409-a6b6-4cf0-9651-13535329f02d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T04:09:21.951898Z",
     "iopub.status.busy": "2024-05-02T04:09:21.951329Z",
     "iopub.status.idle": "2024-05-02T04:09:22.081278Z",
     "shell.execute_reply": "2024-05-02T04:09:22.080475Z",
     "shell.execute_reply.started": "2024-05-02T04:09:21.951834Z"
    }
   },
   "source": [
    "# Light Beads Microscopy Demo Pipeline \n",
    "\n",
    "## Overview\n",
    "### Pre-Processing:\n",
    "- Extract ScanImage metadata\n",
    "- Correct Bi-Directional Offset for each ROI\n",
    "- Calculates and corrects the MROI seams (IN PROGRESS)\n",
    "### Motion Correction\n",
    "- Apply the nonrigid motion correction (NoRMCorre) algorithm for motion correction.\n",
    "- View pre/most correction movie\n",
    "- Use quality metrics to evaluate registration quality\n",
    "### Segmentation\n",
    "- Apply the constrained nonnegative matrix factorization (CNMF) source separation algorithm to extract initial estimates of neuronal spatial footprints and calcium traces.\n",
    "- Apply quality control metrics to evaluate the initial estimates, and narrow down to the final set of estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfb1f45-43a2-463c-8924-b92519434c37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T04:09:21.951898Z",
     "iopub.status.busy": "2024-05-02T04:09:21.951329Z",
     "iopub.status.idle": "2024-05-02T04:09:22.081278Z",
     "shell.execute_reply": "2024-05-02T04:09:22.080475Z",
     "shell.execute_reply.started": "2024-05-02T04:09:21.951834Z"
    }
   },
   "source": [
    "### Setup\n",
    "- Import necessary libraries\n",
    "\n",
    "Notable: Numpy, Cv2, Zarr, Dask, Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c63dc97d-3aa9-4955-8bac-9d67ed6fc427",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T02:20:04.136311883Z",
     "start_time": "2024-05-02T02:20:03.879794240Z"
    },
    "execution": {
     "iopub.execute_input": "2024-05-22T16:42:44.776545Z",
     "iopub.status.busy": "2024-05-22T16:42:44.774034Z",
     "iopub.status.idle": "2024-05-22T16:43:05.233311Z",
     "shell.execute_reply": "2024-05-22T16:43:05.232379Z",
     "shell.execute_reply.started": "2024-05-22T16:42:44.776329Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psutil\n",
    "\n",
    "# Give this notebook access to the root package\n",
    "sys.path.append('../../')  # TODO: Take this out when we upload to pypi\n",
    "print(sys.path[0])\n",
    "\n",
    "import core.io\n",
    "import scanreader\n",
    "\n",
    "import zarr\n",
    "import bokeh.plotting as bpl\n",
    "import holoviews as hv\n",
    "import panel as pn\n",
    "from IPython import get_ipython\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import dask.array as da\n",
    "    has_dask = True\n",
    "except ImportError:\n",
    "    has_dask = False\n",
    "\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except():\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "        get_ipython().run_line_magic('autoreload', '2')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "bpl.output_notebook()\n",
    "hv.notebook_extension('bokeh')\n",
    "\n",
    "# logging\n",
    "logging.basicConfig(format=\"{asctime} - {levelname} - [{filename} {funcName}() {lineno}] - pid {process} - {message}\",\n",
    "                    filename=None, \n",
    "                    level=logging.WARNING, style=\"{\") # this shows you just errors that can harm your program\n",
    "                    # level=logging.DEBUG, style=\"{\") # this shows you general information that developers use to trakc their program \n",
    "                    # (be careful when playing movies, there will be a lot of debug messages)\n",
    "\n",
    "# set env variables \n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"\n",
    "\n",
    "# this session had output planes ordered differently, we need to reorder them\n",
    "chan_order = np.array([ 1, 5, 6, 7, 8, 9, 2, 10, 11, 12, 13, 14, 15, 16, 17, 3, 18, 19, 20, 21, 22, 23, 4, 24, 25, 26, 27, 28, 29, 30])  # this is specific to our dataset\n",
    "chan_order = [x-1 for x in chan_order]  # convert to 0-based indexing"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "03dbfff6-d7d8-4196-80d6-7ce80ebc25a8",
   "metadata": {},
   "source": [
    "## Extract data using scanreader, joining contiguous ROI's, and plot our mean image\n",
    "\n",
    "Our ScanReader object contains all of the properties needed to keep track of our raw data. \n",
    "- ScanImage metadata is stored alongside header metadata, this ScanImage specific data is what's needed to assemble frames from constituent ROIs.\n",
    "- We calculate the frame rate and time/pixels between scans and ROI's using the following metadata:\n",
    "\n",
    "![frame rate calculation](../../docs/img/FrameRate1eq.png)\n",
    "\n",
    "\n",
    "#### Joining Contiguious ROI's\n",
    "\n",
    "Setting `join_contiguous=True` will combine ROI's with the following constraints:\n",
    "\n",
    "1) Must be the same size/shape\n",
    "2) Must be located in the same scanning depth\n",
    "3) Must be located in the same slice\n",
    "- ROI can be directly left, right, above or below the adjacent ROI's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d793259b-40d7-4a9b-8d84-2c6a921f9e11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T17:44:41.877243Z",
     "iopub.status.busy": "2024-05-22T17:44:41.876676Z",
     "iopub.status.idle": "2024-05-22T17:44:42.747711Z",
     "shell.execute_reply": "2024-05-22T17:44:42.746377Z",
     "shell.execute_reply.started": "2024-05-22T17:44:41.877171Z"
    }
   },
   "source": [
    "overwrite = False                                 # flag to re-extract tiffs with extracted data\n",
    "\n",
    "datapath = Path('/data2/fpo/data/raw/high_res/')   # string pointing to directory containing your data\n",
    "savepath = Path('/data2/fpo/data/extraction/')           # string pointing to directory containing your data\n",
    "savepath.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "htiffs = [x for x in datapath.glob('*.tif')]      # this accumulates a list of every filepath which contains a .tif file\n",
    "reader = scanreader.read_scan(str(htiffs[0]), join_contiguous=True, lbm=True, x_cut=(6,6))  # this should take < 2s, no actual data is being read yet"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25986b5f-a5fc-4fe8-bbb8-402c7b6648da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T17:44:53.456071Z",
     "iopub.status.busy": "2024-05-22T17:44:53.455374Z",
     "iopub.status.idle": "2024-05-22T17:44:53.727000Z",
     "shell.execute_reply": "2024-05-22T17:44:53.725867Z",
     "shell.execute_reply.started": "2024-05-22T17:44:53.456008Z"
    }
   },
   "source": [
    "reader"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccfacfb9-33e4-489b-831f-bd9fc6a7b649",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T17:44:55.767127Z",
     "iopub.status.busy": "2024-05-22T17:44:55.765493Z",
     "iopub.status.idle": "2024-05-22T17:49:08.069791Z",
     "shell.execute_reply": "2024-05-22T17:49:08.067693Z",
     "shell.execute_reply.started": "2024-05-22T17:44:55.766977Z"
    }
   },
   "source": [
    "data = reader[0]                                 # here, data is being read"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "80ae37c6",
   "metadata": {},
   "source": [
    "### Data Storage: Zarr\n",
    "\n",
    "[Zarr documentation](https://zarr.readthedocs.io/en/stable/tutorial.html)\n",
    "\n",
    "Deciding how to save data on a host operating system is far from straight foreward. Read/write operations will vary widely between data saved in a **single file**\n",
    "structure vs smaller chunks, e.g. one image per file, one image per epoch, etc. \n",
    " \n",
    "The former strategy is clean/consice and easy to handle but is *not* feasable with large (>10GB) datasets. \n",
    "\n",
    "The latter strategy of spreading files acrossed nested groups of directories, each with their own metadata/attributes has been widely adopted as the more sensible approach. HDF5 has \n",
    "been the frontrunner in scientific data I/O but suffers from widely inconsistent within academia.  \n",
    "\n",
    "- Zarr, similar to H5, is a heirarchical data storage specification (or in non-alien speak: \"rules of how data is stored on disk\").\n",
    "- Zarr nicely hides the complexities inherent in linking filesystem heirarchy with efficient data I/O.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf160b2-18d9-4919-b147-1b7f77df5285",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:42:51.271564Z",
     "iopub.status.idle": "2024-05-22T17:42:51.272004Z",
     "shell.execute_reply": "2024-05-22T17:42:51.271798Z",
     "shell.execute_reply.started": "2024-05-22T17:42:51.271772Z"
    }
   },
   "source": [
    "data.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9f2f735-b346-4edd-b7a8-9d35c14a702d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T16:46:59.225202Z",
     "iopub.status.busy": "2024-05-22T16:46:59.224864Z",
     "iopub.status.idle": "2024-05-22T16:48:03.080306Z",
     "shell.execute_reply": "2024-05-22T16:48:03.079019Z",
     "shell.execute_reply.started": "2024-05-22T16:46:59.225154Z"
    }
   },
   "source": [
    "# Save raw data to persisten zarr store\n",
    "save_str = savepath / \"extracted.zarr\"\n",
    "save_str\n",
    "\n",
    "store = zarr.DirectoryStore(str(save_str))  # save data to persistent disk storage\n",
    "z = zarr.zeros(data.shape, chunks=(data.shape[0], data.shape[1], 1, data.shape[3]), dtype='int16', store=store, overwrite=True)\n",
    "z[:] = data             # this will auto-chunk based on the specified chunks in 'open'"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9fc1830e-81e4-40ca-890c-f12b62059acf",
   "metadata": {},
   "source": [
    "Our daw data can now be accessed through the filepath stored in `save_str`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3bcb645",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T17:33:25.766144Z",
     "iopub.status.busy": "2024-05-22T17:33:25.765327Z",
     "iopub.status.idle": "2024-05-22T17:33:25.922475Z",
     "shell.execute_reply": "2024-05-22T17:33:25.921270Z",
     "shell.execute_reply.started": "2024-05-22T17:33:25.766047Z"
    }
   },
   "source": [
    "save_str"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4e0bb012-8c29-4ac0-bf69-b0fcb3f8cda4",
   "metadata": {},
   "source": [
    "And its parent directory organizes the types of data we're storeing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a56b3c-596b-4edc-9a0b-4692909a5d98",
   "metadata": {},
   "source": [
    "### Leverage zarr directory storage to compare pixel trimming\n",
    "\n",
    "- `zarr.open` is a convenience method that handles chunking and compression for persistant storage.\n",
    "- We want to keep this data as `16 bit` integers because no calculations should be done yet.\n",
    "\n",
    "In general, we want this value to be `~1Mb` to optimize write speed. \n",
    "\n",
    "```python\n",
    "name = '/path/to/folder'\n",
    "chunksize=[300,300,1,1]\n",
    "z1 = zarr.open(f'{name}', mode='w', shape=(data.shape),chunks=chunksize, dtype='int16')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac12b9cd",
   "metadata": {},
   "source": [
    "px_save_dir = savepath / \"pixel_trims\"\n",
    "px_save_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# create a zarr dataset with a variable number of cut pixels\n",
    "x_pixels_to_cut = range(1, 6)\n",
    "for i in x_pixels_to_cut:\n",
    "    # check for the existence of this file before any data is read\n",
    "    px_save_str = px_save_dir / f'px_{i}.zarr'\n",
    "    store = zarr.DirectoryStore(px_save_str)  # save data to persistent disk storage\n",
    "    \n",
    "    reader = scanreader.read_scan(str(htiffs[0]), join_contiguous=True, lbm=True, x_cut=(1,i))  # this should take < 2s, no actual data is being read yet\n",
    "    data = reader[0]                                         # here, data is being read\n",
    "    \n",
    "    z = zarr.zeros(data.shape, chunks=(data.shape[0], data.shape[1], 1, data.shape[3]), dtype='int16', store=store, overwrite=True)\n",
    "    z[:] = data             # this will auto-chunk based on the specified chunks in 'open'"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63909dc2-e987-4c5f-b95a-3276450c7043",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.073298Z",
     "iopub.status.idle": "2024-05-22T17:24:28.073792Z",
     "shell.execute_reply": "2024-05-22T17:24:28.073572Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.073545Z"
    }
   },
   "source": [
    "px_save_dir"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a55fa416",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T17:35:17.109429Z",
     "iopub.status.busy": "2024-05-22T17:35:17.108696Z",
     "iopub.status.idle": "2024-05-22T17:35:22.495821Z",
     "shell.execute_reply": "2024-05-22T17:35:22.494667Z",
     "shell.execute_reply.started": "2024-05-22T17:35:17.109357Z"
    }
   },
   "source": [
    "# helpful command to print the directory content. \n",
    "# place the output of the above cell, your savepath, without the quotes\n",
    "!tree -L 1 /data2/fpo/data/extracted/raw.zarr"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "884ce2fa",
   "metadata": {},
   "source": [
    "## Visualize Initial Pixel Cuts\n",
    "\n",
    "We can see that there is a `name_N.zarr` with a variable number of X pixels trimmed on each ROI.\n",
    "\n",
    "Using [HoloViews](https://holoviews.org/getting_started/), we can create an interactive plot to compare the different numbers of pixels cut on each ROI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a2828f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.076457Z",
     "iopub.status.idle": "2024-05-22T17:24:28.076874Z",
     "shell.execute_reply": "2024-05-22T17:24:28.076674Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.076650Z"
    }
   },
   "source": [
    "@pn.cache\n",
    "def get_plot(i):\n",
    "    arr = zarr.open(str(px_save_dir / f'px_{i}.zarr'), mode='r')\n",
    "    return hv.Image(arr[:,:,5,400]).opts(\n",
    "                width=600,\n",
    "                height=600,\n",
    "                title=f\"pixels_cut: {i}\",\n",
    "                cmap='gray', \n",
    "                tools=['wheel_zoom'],\n",
    "            )\n",
    "\n",
    "# Widgets\n",
    "image_widget = pn.widgets.IntSlider(name=\"Number of cut pixels: \", value=1, start=1, end=6)\n",
    "bound_plot = pn.bind(get_plot, i=image_widget) \n",
    "\n",
    "# Layout of widgets and plot\n",
    "layout = pn.Column(\n",
    "    pn.Row(image_widget, sizing_mode=\"fixed\", width=500),\n",
    "    bound_plot\n",
    ")\n",
    "\n",
    "# Display the layout\n",
    "layout.servable()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "dc9a7e9f",
   "metadata": {},
   "source": [
    "# Benchmark: Chunk Sizes\n",
    "\n",
    "The below section demonstrates how to search for the optimal data chunking/partitioning scheme for our datasets.\n",
    "\n",
    "- Chunking by **Image**:\n",
    "\n",
    "  The smallest chunks we have. Each image is loaded in parallel, which requires many cores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54805353-9c74-475e-bbdb-605fdb6ebb61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T17:35:38.196314Z",
     "iopub.status.busy": "2024-05-22T17:35:38.195073Z",
     "iopub.status.idle": "2024-05-22T17:35:38.335561Z",
     "shell.execute_reply": "2024-05-22T17:35:38.334857Z",
     "shell.execute_reply.started": "2024-05-22T17:35:38.196139Z"
    }
   },
   "source": [
    "# directory to save our benchmarks\n",
    "benchmarks_savedir = datapath / 'benchmarks'\n",
    "benchmarks_savedir.mkdir(exist_ok=True, parents=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec12ca9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T15:50:41.914458Z",
     "start_time": "2024-05-07T15:50:41.833759Z"
    },
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.079305Z",
     "iopub.status.idle": "2024-05-22T17:24:28.079724Z",
     "shell.execute_reply": "2024-05-22T17:24:28.079526Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.079502Z"
    }
   },
   "source": [
    "# Helper function to process a dataset\n",
    "# Data can be any numpy or numpy-like array\n",
    "\n",
    "def benchmark_chunk_sizes(data, chunk_shape, savepath='', overwrite=True):\n",
    "    savepath = Path(savepath).with_suffix('.zarr')\n",
    "    \n",
    "    # benchmark write\n",
    "    start = time.time()\n",
    "    store = zarr.DirectoryStore(savepath)  # save data to persistent disk storage\n",
    "    z = zarr.zeros(data.shape, chunks=chunk_shape, dtype='int16', store=store, overwrite=overwrite)\n",
    "\n",
    "    if hasattr(data, 'compute'):\n",
    "        z[:] = data.compute()             # this will auto-chunk based on the specified chunks in 'open'\n",
    "    else:\n",
    "        z[:] = data\n",
    "\n",
    "    write = time.time() - start\n",
    "    formatted_write = f\"{write:.2f}\"\n",
    "\n",
    "    # benchmark read\n",
    "    start = time.time()\n",
    "    _ = z[:]\n",
    "    read = time.time() - start\n",
    "    formatted_read = f\"{read:.2f}\"\n",
    "\n",
    "    chunksize_nbytes = np.prod(chunk_shape) * z.dtype.itemsize  # 2 bytes per int16\n",
    "    return [\n",
    "        str(data.shape),\n",
    "        str(z.chunks),\n",
    "        z.nbytes / 1e6,\n",
    "        chunksize_nbytes / 1e6,\n",
    "        z.dtype,\n",
    "        z.order,\n",
    "        formatted_read,\n",
    "        formatted_write,\n",
    "        z.store.path\n",
    "    ]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e7ce8295",
   "metadata": {},
   "source": [
    "Use our raw dataset to get image shapes, and read/write operation on the **same dataset** with different chunk sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352eb260-2181-4a28-b57a-e269b141ef0b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.080455Z",
     "iopub.status.idle": "2024-05-22T17:24:28.080869Z",
     "shell.execute_reply": "2024-05-22T17:24:28.080670Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.080646Z"
    }
   },
   "source": [
    "# we use dimensions from our initial raw data store\n",
    "zinf = zarr.open(save_str)\n",
    "zinf.chunks"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75598193",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.081565Z",
     "iopub.status.idle": "2024-05-22T17:24:28.081979Z",
     "shell.execute_reply": "2024-05-22T17:24:28.081783Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.081759Z"
    },
    "scrolled": true
   },
   "source": [
    "labels = [\n",
    "    'Array  [x,y,z,t]',\n",
    "    'Chunks [x,y,z,t]',\n",
    "    'Chunk Size (Mb)',\n",
    "    'Array Size (Mb)',\n",
    "    'Data Type',\n",
    "    'Order',\n",
    "    'Read Time (s)',\n",
    "    'Write Time (s)',\n",
    "    'Save Path'\n",
    "]\n",
    "\n",
    "# the chunk sizes we want to benchmark\n",
    "chunksizes = [\n",
    "    (zinf.shape[0], zinf.shape[1], 1, zinf.shape[3]),  # [300x300x1x1750]\n",
    "    (zinf.shape[0], zinf.shape[1], zinf.shape[2], 1),  # [300x300x30x1  ]\n",
    "    (zinf.shape[0], zinf.shape[1], 1, 1)               # [300x300x1x1   ]\n",
    "]\n",
    "\n",
    "# give our dataset a name. this will be the column header\n",
    "names = [\n",
    "    ('chunked_by_plane'),  # [300x300x1x1750]\n",
    "    ('chunked_by_frame'),  # [300x300x30x1  ]\n",
    "    ('chunked_by_image')   # [300x300x1x1   ]\n",
    "]\n",
    "\n",
    "benchmark_chunks_dir = benchmarks_savedir / \"chunks\"\n",
    "benchmark_chunks_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "vals = {data_name: [] for data_name in names}\n",
    "for i, (chunksize, dataset) in enumerate(zip(chunksizes, names)):\n",
    "    # save the same data but with different chunk sizes\n",
    "    chunks_save = benchmark_chunks_dir / f'{dataset}.zarr'\n",
    "    # new store \n",
    "    store = zarr.DirectoryStore(save_str)  # save data to persistent disk storage\n",
    "    z = zarr.zeros(zinf.shape, chunks=(zinf.shape[0], zinf.shape[1], 1, zinf.shape[3]), dtype='int16', store=store, overwrite=True)\n",
    "    vals[dataset] = benchmark_chunk_sizes(zinf, chunksize, savepath=f\"{chunks_save}\", overwrite=True)\n",
    "\n",
    "df = pd.DataFrame(index=labels, columns=names, data=None)\n",
    "for k, v in vals.items():\n",
    "    df[k] = v\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528f9c10-e444-4663-b7e8-aa32ada47cf5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.083034Z",
     "iopub.status.idle": "2024-05-22T17:24:28.083462Z",
     "shell.execute_reply": "2024-05-22T17:24:28.083255Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.083231Z"
    }
   },
   "source": [
    "df"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c7ed22d9",
   "metadata": {},
   "source": [
    "### Dask\n",
    "At this point, our zarr array is a \"view\" onto the actual data in memory. We can easily convert it to other data types that operate on the numpy ecosystem, like dask!\n",
    "\n",
    "Dask is a library that will allow us to use numpy-like operations on zarr arrays with the added benefit of internally loading our data lazily, i.e. only when we need it for a computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d886b2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.084247Z",
     "iopub.status.idle": "2024-05-22T17:24:28.084658Z",
     "shell.execute_reply": "2024-05-22T17:24:28.084461Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.084437Z"
    }
   },
   "source": [
    "chunks_save = benchmark_chunks_dir / 'chunked_by_plane.zarr'\n",
    "data_da = da.from_zarr(chunks_save, chunks=zinf.chunks)\n",
    "data_da"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "039fdb8d-75fb-4242-9b74-b28ddcabeb54",
   "metadata": {},
   "source": [
    "## Scan Phase Correction\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### *Methods:*\n",
    "\n",
    "**1) Linear interpolation**\n",
    "\n",
    "**2) Phase - cross correlation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971200fe",
   "metadata": {},
   "source": [
    "### Phase correction via Linear Phase Interpolation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2263b87e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.085926Z",
     "iopub.status.idle": "2024-05-22T17:24:28.086513Z",
     "shell.execute_reply": "2024-05-22T17:24:28.086286Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.086259Z"
    }
   },
   "source": [
    "# the 5 pixel-cut looked the best, lets get that one\n",
    "files = sorted([x for x in savepath.glob(\"**/*.zarr\")])\n",
    "files[4]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7292fdf3-547e-4736-a335-8eee95550a61",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.087461Z",
     "iopub.status.idle": "2024-05-22T17:24:28.087884Z",
     "shell.execute_reply": "2024-05-22T17:24:28.087682Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.087658Z"
    }
   },
   "source": [
    "dataset = files[4]\n",
    "za = zarr.open(str(dataset))\n",
    "za.info"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1575d02",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.088799Z",
     "iopub.status.idle": "2024-05-22T17:24:28.089216Z",
     "shell.execute_reply": "2024-05-22T17:24:28.089018Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.088994Z"
    }
   },
   "source": [
    "array = da.from_array(za, chunks=za.chunks)\n",
    "array"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2e5ac69a",
   "metadata": {},
   "source": [
    "## Scan Phase Correction\n",
    "\n",
    "Until now our data has been in `int16`. Now that we are performing correlations acrossed averaged pixels, we want a more accurate datatype.\n",
    "`compute_raster_phase` will load in the data and convert it to a float intrinsically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dffe34-aa68-4074-88a3-80788bba4209",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.090291Z",
     "iopub.status.idle": "2024-05-22T17:24:28.090729Z",
     "shell.execute_reply": "2024-05-22T17:24:28.090523Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.090498Z"
    }
   },
   "source": [
    "# # TODO: debug why this takes 15min + (way too long)\n",
    "# phase_angle = core.util.compute_raster_phase(array[:,:, 5, 400].compute(), reader.temporal_fill_fraction)\n",
    "# corrected_li = core.util.correct_raster(array, phase_angle, reader.temporal_fill_fraction)\n",
    "# phase_angle"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb5a902",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.091624Z",
     "iopub.status.idle": "2024-05-22T17:24:28.092042Z",
     "shell.execute_reply": "2024-05-22T17:24:28.091842Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.091818Z"
    }
   },
   "source": [
    "corr = core.util.return_scan_offset(array[:,:,5,400].compute(), 1)\n",
    "corrected_pc = core.util.fix_scan_phase(array, corr, 1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ee6d0d64-8584-43ec-bfa7-51e06604567d",
   "metadata": {},
   "source": [
    "## Motion Correction: CaImAn - NORMCorre\n",
    "\n",
    "Load pre-processed data as a CaImAn `movie`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37bd042",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.092876Z",
     "iopub.status.idle": "2024-05-22T17:24:28.093288Z",
     "shell.execute_reply": "2024-05-22T17:24:28.093092Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.093068Z"
    }
   },
   "source": [
    "import caiman as cm\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.source_extraction.cnmf import cnmf, params\n",
    "from caiman.utils.utils import download_demo\n",
    "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
    "from caiman.utils.visualization import view_quilt"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b5d89e8c",
   "metadata": {},
   "source": [
    "Before motion correction, lets see what volumes look like interactively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4f5fd49",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-05-22T17:36:22.405727Z",
     "iopub.status.busy": "2024-05-22T17:36:22.404961Z",
     "iopub.status.idle": "2024-05-22T17:36:23.103122Z",
     "shell.execute_reply": "2024-05-22T17:36:23.102182Z",
     "shell.execute_reply.started": "2024-05-22T17:36:22.405661Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "@pn.cache\n",
    "def get_plot_plane(plane=1, frame=1, title=\"\"):\n",
    "    return hv.Image(data[:,:,plane,frame]).opts(\n",
    "                width=600,\n",
    "                height=600,\n",
    "                title=f\"{title}\",\n",
    "                tools=['wheel_zoom'],\n",
    "                cmap='gray', \n",
    "            )\n",
    "\n",
    "# Widgets\n",
    "plane_slider = pn.widgets.IntSlider(name=\"plane: \", value=1, start=1, end=9)\n",
    "frame_slider = pn.widgets.IntSlider(name=\"frame: \", value=1, start=1, end=9)\n",
    "\n",
    "bound_plot = pn.bind(get_plot_plane, frame=frame_slider, plane=plane_slider) \n",
    "\n",
    "# Layout of widgets and plot\n",
    "layout = pn.Column(\n",
    "    pn.Row(plane_slider, width=200),\n",
    "    pn.Row(frame_slider, width=200),\n",
    "    bound_plot\n",
    ")\n",
    "\n",
    "# Display the layout\n",
    "layout.servable()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aef410d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.095687Z",
     "iopub.status.idle": "2024-05-22T17:24:28.096107Z",
     "shell.execute_reply": "2024-05-22T17:24:28.095907Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.095883Z"
    },
    "scrolled": true
   },
   "source": [
    "help(MotionCorrect)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "25b14011",
   "metadata": {},
   "source": [
    "## Correlation metrics\n",
    "\n",
    "Create a couple of summary images of the movie, including:\n",
    "- maximum projection (the maximum value of each pixel) \n",
    "- correlation image (how correlated each pixel is with its neighbors)\n",
    "\n",
    "If a pixel comes from an active neural component it will tend to be highly correlated with its neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5be6cf",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.096971Z",
     "iopub.status.idle": "2024-05-22T17:24:28.097389Z",
     "shell.execute_reply": "2024-05-22T17:24:28.097190Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.097166Z"
    }
   },
   "source": [
    "plane_arr = data[:,:,5,5:1000]\n",
    "max_projection = np.max(plane_arr, axis=0)  # 3D -> 2D"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dea1a8e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.098420Z",
     "iopub.status.idle": "2024-05-22T17:24:28.098851Z",
     "shell.execute_reply": "2024-05-22T17:24:28.098648Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.098624Z"
    }
   },
   "source": [
    "correlation_image = cm.local_correlations(plane_arr, swap_dim=False)\n",
    "correlation_image[np.isnan(correlation_image)] = 0 "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01051dd",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.100310Z",
     "iopub.status.idle": "2024-05-22T17:24:28.177227Z",
     "shell.execute_reply": "2024-05-22T17:24:28.176700Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.176607Z"
    }
   },
   "source": [
    "%matplotlib inline\n",
    "f, (ax_max, ax_corr) = plt.subplots(1,2)\n",
    "ax_max.imshow(max_projection.T, \n",
    "              cmap='viridis',\n",
    "              vmin=np.percentile(np.ravel(max_projection),50), \n",
    "              vmax=np.percentile(np.ravel(max_projection),99.5));\n",
    "ax_max.set_title(\"Max Projection Orig\", fontsize=12)\n",
    "ax_corr.imshow(correlation_image.T, \n",
    "               cmap='viridis', \n",
    "               vmin=np.percentile(np.ravel(correlation_image),50), \n",
    "               vmax=np.percentile(np.ravel(correlation_image),99.5))\n",
    "ax_corr.set_title('Correlation Image Orig', fontsize=12)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a226c084",
   "metadata": {},
   "source": [
    "### Parameter Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879f9a14",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.178781Z",
     "iopub.status.idle": "2024-05-22T17:24:28.179646Z",
     "shell.execute_reply": "2024-05-22T17:24:28.179231Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.179181Z"
    }
   },
   "source": [
    "max_shifts = (6, 6)  # maximum allowed rigid shift in pixels (view the movie to get a sense of motion)\n",
    "strides =  (48, 48)  # create a new patch every x pixels for pw-rigid correction\n",
    "overlaps = (24, 24)  # overlap between patches (size of patch strides+overlaps)\n",
    "max_deviation_rigid = 3   # maximum deviation allowed for patch with respect to rigid shifts\n",
    "pw_rigid = False  # flag for performing rigid or piecewise rigid motion correction\n",
    "shifts_opencv = True  # flag for correcting motion using bicubic interpolation (otherwise FFT interpolation is used)\n",
    "border_nan = 'copy'  # replicate values along the boundary (if True, fill in with NaN)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478f8db0-c0d9-432c-9540-bf35657c9b18",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.181223Z",
     "iopub.status.idle": "2024-05-22T17:24:28.182066Z",
     "shell.execute_reply": "2024-05-22T17:24:28.181663Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.181612Z"
    }
   },
   "source": [
    "file_in = [x for x in savepath.glob(\"*.zarr\")]\n",
    "file_in[0]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "79c6cfc7-941c-4fdf-9d8f-d65179155a44",
   "metadata": {},
   "source": [
    "## Save as a tiff, for now \n",
    "\n",
    "TODO: why is caiman not recognizing the zarr group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc97285-1097-48b6-95ed-190a29571e46",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.188050Z",
     "iopub.status.idle": "2024-05-22T17:24:28.188933Z",
     "shell.execute_reply": "2024-05-22T17:24:28.188520Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.188470Z"
    }
   },
   "source": [
    "import tifffile\n",
    "fpath = Path('/data2/fpo/data/raw/raw.tiff')\n",
    "fpath.exists()\n",
    "    \n",
    "data_plane = data[:,:,5,2:1002]\n",
    "data_plane = data_plane.reshape((data_plane.shape[-1], data_plane.shape[0], data_plane.shape[1]))\n",
    "tifffile.imwrite(fpath, data_plane)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfd7c81",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.190362Z",
     "iopub.status.idle": "2024-05-22T17:24:28.191224Z",
     "shell.execute_reply": "2024-05-22T17:24:28.190819Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.190769Z"
    }
   },
   "source": [
    "#%% start the cluster (if a cluster already exists terminate it)\n",
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='multiprocessing', n_processes=None, single_thread=False)\n",
    "# create a motion correction object\n",
    "\n",
    "mc = MotionCorrect(str(fpath), dview=dview, max_shifts=max_shifts,\n",
    "                  strides=strides, overlaps=overlaps,\n",
    "                  max_deviation_rigid=max_deviation_rigid, \n",
    "                  shifts_opencv=shifts_opencv, nonneg_movie=True,\n",
    "                  border_nan=border_nan)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8c02e6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.192786Z",
     "iopub.status.idle": "2024-05-22T17:24:28.193627Z",
     "shell.execute_reply": "2024-05-22T17:24:28.193225Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.193175Z"
    },
    "scrolled": true
   },
   "source": [
    "%%capture\n",
    "# correct for rigid motion correction and save the file (in memory mapped form)\n",
    "mc.motion_correct(save_movie=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7777fe6d-d767-4212-a56d-f32e6a2ed627",
   "metadata": {},
   "source": [
    "### View rigid template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1764276b-63bb-4622-a0c9-6c324ae8f5fc",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.195089Z",
     "iopub.status.idle": "2024-05-22T17:24:28.195931Z",
     "shell.execute_reply": "2024-05-22T17:24:28.195527Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.195476Z"
    }
   },
   "source": [
    "# load motion corrected movie\n",
    "m_rig = cm.load(mc.mmap_file)\n",
    "bord_px_rig = np.ceil(np.max(mc.shifts_rig)).astype(int)\n",
    "#%% visualize templates\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.imshow(mc.total_template_rig, cmap = 'gray');"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2c4ccaff-4744-42d1-a681-6be22858225f",
   "metadata": {},
   "source": [
    "Rigid-corrected movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156cfa3d-9b85-4573-a303-d51a033134fc",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.197332Z",
     "iopub.status.idle": "2024-05-22T17:24:28.198170Z",
     "shell.execute_reply": "2024-05-22T17:24:28.197773Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.197723Z"
    }
   },
   "source": [
    "#%% inspect movie\n",
    "m_rig.resize(1, 1, downsample_ratio).play(\n",
    "    q_max=99.5, fr=30, magnification=2, bord_px = 0*bord_px_rig) # press q to exit"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "344eec9d-af39-4fc9-9e40-a041d482dc1b",
   "metadata": {},
   "source": [
    "Rigid Template shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c15518-000b-41cc-b1d5-10dceb66ad87",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.199566Z",
     "iopub.status.idle": "2024-05-22T17:24:28.200399Z",
     "shell.execute_reply": "2024-05-22T17:24:28.200002Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.199951Z"
    }
   },
   "source": [
    "#%% plot rigid shifts\n",
    "plt.close()\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.plot(mc.shifts_rig)\n",
    "plt.legend(['x shifts','y shifts'])\n",
    "plt.xlabel('frames')\n",
    "plt.ylabel('pixels');"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b8b4223a-7da5-4daa-a526-4461184c0a8d",
   "metadata": {},
   "source": [
    "\n",
    "## Piecewise rigid registration\n",
    "\n",
    "While rigid registration corrected for a lot of the movement, there is still non-uniform motion present in the registered file.\n",
    "\n",
    "- To correct for that we can use piece-wise rigid registration directly in the original file by setting mc.pw_rigid=True.\n",
    "- As before the registered file is saved in a memory mapped format in the location given by mc.mmap_file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3df52d6-a545-452f-a197-f273723550eb",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.201907Z",
     "iopub.status.idle": "2024-05-22T17:24:28.202761Z",
     "shell.execute_reply": "2024-05-22T17:24:28.202342Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.202292Z"
    }
   },
   "source": [
    "%%capture\n",
    "#%% motion correct piecewise rigid\n",
    "mc.pw_rigid = True  # turn the flag to True for pw-rigid motion correction\n",
    "mc.template = mc.mmap_file  # use the template obtained before to save in computation (optional)\n",
    "\n",
    "mc.motion_correct(save_movie=True, template=mc.total_template_rig)\n",
    "m_els = cm.load(mc.fname_tot_els)\n",
    "m_els.resize(1, 1, downsample_ratio).play(\n",
    "    q_max=99.5, fr=30, magnification=2,bord_px = bord_px_rig)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "840863fc-9368-4e01-be0d-ebb5ca1961a0",
   "metadata": {},
   "source": [
    "visualize non-rigid shifts for the entire FOV\n",
    "\n",
    "TODO: Interactively visualize rigid+non-rigid shifts independantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9cb191-fa95-4e92-96c2-ffb9b9fc008d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.204157Z",
     "iopub.status.idle": "2024-05-22T17:24:28.204985Z",
     "shell.execute_reply": "2024-05-22T17:24:28.204589Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.204538Z"
    }
   },
   "source": [
    "plt.close()\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(mc.x_shifts_els)\n",
    "plt.ylabel('x shifts (pixels)')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(mc.y_shifts_els)\n",
    "plt.ylabel('y_shifts (pixels)')\n",
    "plt.xlabel('frames')\n",
    "#%% compute borders to exclude\n",
    "bord_px_els = np.ceil(np.maximum(np.max(np.abs(mc.x_shifts_els)),\n",
    "                                 np.max(np.abs(mc.y_shifts_els)))).astype(int)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3d225ca6-6f60-42ae-8551-113fac7b3083",
   "metadata": {},
   "source": [
    "## Motion Corretion: Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74be0b7-41fe-4d4f-a415-184da72283e2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.206388Z",
     "iopub.status.idle": "2024-05-22T17:24:28.207242Z",
     "shell.execute_reply": "2024-05-22T17:24:28.206836Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.206785Z"
    }
   },
   "source": [
    "#%% plot the results of Residual Optical Flow\n",
    "fls = [cm.paths.fname_derived_presuffix(mc.fname_tot_els[0], 'metrics', swapsuffix='npz'),\n",
    "       cm.paths.fname_derived_presuffix(mc.fname_tot_rig[0], 'metrics', swapsuffix='npz'),\n",
    "       cm.paths.fname_derived_presuffix(mc.fname[0],         'metrics', swapsuffix='npz'),\n",
    "      ]\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "for cnt, fl, metr in zip(range(len(fls)), fls, ['pw_rigid','rigid','raw']):\n",
    "    with np.load(fl) as ld:\n",
    "        print(ld.keys())\n",
    "        print(fl)\n",
    "        print(str(np.mean(ld['norms'])) + '+/-' + str(np.std(ld['norms'])) +\n",
    "              ' ; ' + str(ld['smoothness']) + ' ; ' + str(ld['smoothness_corr']))\n",
    "        \n",
    "        plt.subplot(len(fls), 3, 1 + 3 * cnt)\n",
    "        plt.ylabel(metr)\n",
    "        print(f\"Loading data with base {fl[:-12]}\")\n",
    "        try:\n",
    "            mean_img = np.mean(\n",
    "            cm.load(fl[:-12] + '.mmap'), 0)[12:-12, 12:-12]\n",
    "        except:\n",
    "            try:\n",
    "                mean_img = np.mean(\n",
    "                    cm.load(fl[:-12] + '.tif'), 0)[12:-12, 12:-12]\n",
    "            except:\n",
    "                mean_img = np.mean(\n",
    "                    cm.load(fl[:-12] + 'hdf5'), 0)[12:-12, 12:-12]\n",
    "                    \n",
    "        lq, hq = np.nanpercentile(mean_img, [.5, 99.5])\n",
    "        plt.imshow(mean_img, vmin=lq, vmax=hq)\n",
    "        plt.title('Mean')\n",
    "        plt.subplot(len(fls), 3, 3 * cnt + 2)\n",
    "        plt.imshow(ld['img_corr'], vmin=0, vmax=.35)\n",
    "        plt.title('Corr image')\n",
    "        plt.subplot(len(fls), 3, 3 * cnt + 3)\n",
    "        flows = ld['flows']\n",
    "        plt.imshow(np.mean(\n",
    "        np.sqrt(flows[:, :, :, 0]**2 + flows[:, :, :, 1]**2), 0), vmin=0, vmax=0.3)\n",
    "        plt.colorbar()\n",
    "        plt.title('Mean optical flow');  "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348a95f8-ccbe-4d1a-a9aa-88405001b045",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.208676Z",
     "iopub.status.idle": "2024-05-22T17:24:28.209831Z",
     "shell.execute_reply": "2024-05-22T17:24:28.209425Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.209373Z"
    }
   },
   "source": [
    "## Run CNMF on patches in parallel"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2c073dc3",
   "metadata": {},
   "source": [
    "# Cleanup\n",
    "\n",
    "Make sure our parallel cluster is shut down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99671c6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-22T17:24:28.211494Z",
     "iopub.status.idle": "2024-05-22T17:24:28.212334Z",
     "shell.execute_reply": "2024-05-22T17:24:28.211928Z",
     "shell.execute_reply.started": "2024-05-22T17:24:28.211878Z"
    },
    "scrolled": true
   },
   "source": [
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "elif 'cluster' in locals():\n",
    "    cm.stop_server(dview=cluster)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
