{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91da1896-5101-45a8-8597-913d5844dc9c",
   "metadata": {
    "execution": {
     "execution_failed": "2024-05-23T17:59:58.095Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psutil\n",
    "\n",
    "# Give this notebook access to the root package\n",
    "sys.path.append('../../')  # TODO: Take this out when we upload to pypi\n",
    "print(sys.path[0])\n",
    "\n",
    "import core.io\n",
    "import scanreader\n",
    "\n",
    "import zarr\n",
    "import bokeh.plotting as bpl\n",
    "import holoviews as hv\n",
    "import panel as pn\n",
    "from IPython import get_ipython\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import dask.array as da\n",
    "    has_dask = True\n",
    "except ImportError:\n",
    "    has_dask = False\n",
    "\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except():\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "        get_ipython().run_line_magic('autoreload', '2')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "bpl.output_notebook()\n",
    "hv.notebook_extension('bokeh')\n",
    "\n",
    "# logging\n",
    "logging.basicConfig(format=\"{asctime} - {levelname} - [{filename} {funcName}() {lineno}] - pid {process} - {message}\",\n",
    "                    filename=None, \n",
    "                    level=logging.WARNING, style=\"{\") # this shows you just errors that can harm your program\n",
    "                    # level=logging.DEBUG, style=\"{\") # this shows you general information that developers use to trakc their program \n",
    "                    # (be careful when playing movies, there will be a lot of debug messages)\n",
    "\n",
    "# set env variables \n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"\n",
    "\n",
    "# this session had output planes ordered differently, we need to reorder them\n",
    "chan_order = np.array([ 1, 5, 6, 7, 8, 9, 2, 10, 11, 12, 13, 14, 15, 16, 17, 3, 18, 19, 20, 21, 22, 23, 4, 24, 25, 26, 27, 28, 29, 30])  # this is specific to our dataset\n",
    "chan_order = [x-1 for x in chan_order]  # convert to 0-based indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555a7ee4-89eb-460c-a66d-aedce0fae6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = False                                 # flag to re-extract tiffs with extracted data\n",
    "\n",
    "datapath = Path('/data2/fpo/data/raw/high_res/')   # string pointing to directory containing your data\n",
    "savepath = Path('/data2/fpo/data/extraction/')           # string pointing to directory containing your data\n",
    "savepath.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "htiffs = [x for x in datapath.glob('*.tif')]      # this accumulates a list of every filepath which contains a .tif file\n",
    "reader = scanreader.read_scan(str(htiffs[0]), join_contiguous=True, lbm=True, x_cut=(6,6), y_cut=(17,0))  # this should take < 2s, no actual data is being read yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7a04bd-3d55-4fa6-9818-b43b20eaf81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plane = reader[:, :, :, :, :]\n",
    "data_plane"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": ""
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
