{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LBM-CaImAn Pipeline Demo\n",
    "\n",
    "calcium imaging segmentation pipeline using CaImAn CNMF on light-beads microscopy data.\n",
    "\n",
    "sections:\n",
    "1. load data and inspect metadata\n",
    "2. configure CNMF parameters (neuron size, patch grid, quality thresholds)\n",
    "3. run pipeline\n",
    "4. run component evaluation on existing results\n",
    "5. filter and visualize accepted neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lbm_caiman_python as lcp\n",
    "from mbo_utilities import imread\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"lbm_caiman_python version: {lcp.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = Path(r\"E:\\datasets\\lbm\\jeff_lbm\\caiman\")\n",
    "output_path = Path(r\"E:\\datasets\\lbm\\jeff_lbm\\segmentation-v3\")\n",
    "\n",
    "data = imread(input_path)\n",
    "meta = data.metadata\n",
    "print(f\"Shape: {data.shape}, dtype: {data.dtype}\")\n",
    "print(f\"Frame rate: {meta.get('fr', 'N/A')} Hz\")\n",
    "print(f\"Pixel size: dx={meta.get('dx', 'N/A')} µm, dy={meta.get('dy', 'N/A')} µm\")\n",
    "print(f\"Num planes: {meta.get('num_planes', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure parameters\n",
    "\n",
    "key parameters:\n",
    "- **gSig, gSiz**: neuron half-width and bounding box in pixels, derived from 10-20 µm target and pixel size\n",
    "- **rf, stride, K**: patch grid. rf=half-patch-size, stride=overlap step, K=components per patch.\n",
    "  K is computed from assumed neuron density (92k/mm³) scaled to a single z-slice.\n",
    "  previous run used rf=20 (40px patches) with K=130 which created grid artifacts —\n",
    "  every 3.5 pixels got a component regardless of whether a neuron was there.\n",
    "- **merge_thresh**: spatial correlation threshold for merging duplicate components across patches.\n",
    "  note: the caiman parameter name is `merge_thresh`, not `merge_thr`.\n",
    "- **min_SNR, rval_thr**: quality thresholds for evaluate_components (run automatically after CNMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops = lcp.default_ops()\n",
    "\n",
    "# data metadata\n",
    "ops[\"fr\"] = meta[\"frame_rate\"]\n",
    "ops[\"dxy\"] = (meta[\"dx\"], meta[\"dy\"])\n",
    "ops[\"decay_time\"] = 0.7\n",
    "\n",
    "# neuron size from 10-20 µm target\n",
    "dx = meta[\"dx\"]\n",
    "neuron_min_um, neuron_max_um = 10, 20\n",
    "half_neuron_px = int(round((neuron_min_um / 2) / dx))\n",
    "gSiz_px = int(round(neuron_max_um / dx)) + 1\n",
    "ops[\"gSig\"] = (half_neuron_px, half_neuron_px)\n",
    "ops[\"gSiz\"] = (gSiz_px, gSiz_px)\n",
    "\n",
    "# patch grid — K derived from density\n",
    "patch_side = 80  # pixels per patch side (rf = patch_side // 2)\n",
    "patch_area_mm2 = (patch_side * dx * 1e-3) ** 2\n",
    "neurons_per_patch = int(92000 * patch_area_mm2 * 0.05)  # 92k/mm³, ~50 µm z-slice\n",
    "ops[\"rf\"] = patch_side // 2\n",
    "ops[\"stride\"] = patch_side // 4\n",
    "ops[\"K\"] = max(neurons_per_patch + 10, 30)\n",
    "ops[\"nb\"] = 1\n",
    "\n",
    "# merging and quality\n",
    "ops[\"merge_thresh\"] = 0.85\n",
    "ops[\"min_SNR\"] = 3.0\n",
    "ops[\"rval_thr\"] = 0.8\n",
    "ops[\"p\"] = 1\n",
    "ops[\"ssub\"] = 1\n",
    "ops[\"tsub\"] = 1\n",
    "ops[\"do_motion_correction\"] = False\n",
    "\n",
    "print(f\"Pixel size: {dx:.2f} µm/px\")\n",
    "print(f\"gSig={ops['gSig']} px, gSiz={ops['gSiz']} px\")\n",
    "print(f\"Patch: {patch_side}x{patch_side} px, stride={ops['stride']}, K={ops['K']}\")\n",
    "print(f\"Expected ~{neurons_per_patch} neurons/patch\")\n",
    "print(f\"Quality: min_SNR={ops['min_SNR']}, rval_thr={ops['rval_thr']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = lcp.pipeline(\n",
    "    input_data=input_path,\n",
    "    save_path=output_path,\n",
    "    ops=ops,\n",
    "    planes=[1],\n",
    "    force_mcorr=False,\n",
    "    force_cnmf=False,\n",
    ")\n",
    "\n",
    "print(f\"\\nProcessed {len(results)} plane(s)\")\n",
    "for r in results:\n",
    "    print(f\"  {r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect results\n",
    "if results:\n",
    "    plane_dir = results[0].parent\n",
    "    data = lcp.load_planar_results(plane_dir)\n",
    "    ops_saved = data[\"ops\"]\n",
    "\n",
    "    print(f\"Plane: {ops_saved.get('plane', '?')}\")\n",
    "    print(f\"Total components: {ops_saved.get('n_cells_total', ops_saved.get('n_cells', '?'))}\")\n",
    "    print(f\"Accepted components: {ops_saved.get('n_cells', '?')}\")\n",
    "    print(f\"FOV: {ops_saved.get('Ly', '?')} x {ops_saved.get('Lx', '?')}\")\n",
    "    print(f\"Frames: {ops_saved.get('nframes', '?')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Component evaluation on existing results\n",
    "\n",
    "if the pipeline already ran, load saved estimates and run CaImAn's\n",
    "`evaluate_components` to compute r_values (spatial correlation) and\n",
    "SNR_comp (signal-to-noise) for each component.\n",
    "\n",
    "important: CaImAn's evaluate_components has a bug in its non-memmap\n",
    "code path (assumes d1,d2,T axis order but movie is T,d1,d2). we\n",
    "always load through a CaImAn-format mmap file to avoid this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "import caiman as cm\n",
    "from caiman.source_extraction.cnmf.estimates import Estimates\n",
    "from caiman.source_extraction.cnmf.params import CNMFParams\n",
    "\n",
    "# load saved estimates\n",
    "plane_dir = Path(r\"E:\\datasets\\lbm\\jeff_lbm\\segmentation-v3\\zplane01_tp00001-00500\")\n",
    "data = lcp.load_planar_results(plane_dir)\n",
    "ops_data = data[\"ops\"]\n",
    "estimates_dict = data[\"estimates\"]\n",
    "\n",
    "A = estimates_dict[\"A\"]\n",
    "C = estimates_dict[\"C\"]\n",
    "Ly = ops_data.get(\"Ly\", 1002)\n",
    "Lx = ops_data.get(\"Lx\", 725)\n",
    "print(f\"Raw components: {A.shape[1]}\")\n",
    "print(f\"FOV: {Ly} x {Lx}\")\n",
    "\n",
    "# reconstruct caiman Estimates object\n",
    "est = Estimates(A=A, C=C,\n",
    "                b=estimates_dict.get(\"b\"),\n",
    "                f=estimates_dict.get(\"f\"))\n",
    "if estimates_dict.get(\"S\") is not None:\n",
    "    est.S = estimates_dict[\"S\"]\n",
    "if estimates_dict.get(\"YrA\") is not None:\n",
    "    est.YrA = estimates_dict[\"YrA\"]\n",
    "\n",
    "print(\"Estimates object reconstructed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create or reuse caiman-format mmap from movie\n",
    "raw = imread(input_path)\n",
    "movie = np.asarray(raw[:, 0, :, :]).squeeze().astype(np.float32)\n",
    "T, d1, d2 = movie.shape\n",
    "print(f\"Movie: {movie.shape}\")\n",
    "\n",
    "mmap_path = plane_dir / f\"Yr_d1_{d1}_d2_{d2}_d3_1_order_C_frames_{T}_.mmap\"\n",
    "\n",
    "if not mmap_path.exists():\n",
    "    print(\"Writing mmap...\")\n",
    "    fp = np.memmap(str(mmap_path), mode='w+', dtype=np.float32,\n",
    "                   shape=(d1 * d2, T), order='F')\n",
    "    for t in range(T):\n",
    "        fp[:, t] = movie[t].ravel(order='F')\n",
    "    del fp\n",
    "    print(f\"Created: {mmap_path.name}\")\n",
    "else:\n",
    "    print(f\"Reusing: {mmap_path.name}\")\n",
    "\n",
    "Yr, dims, T_mm = cm.load_memmap(str(mmap_path))\n",
    "images = np.reshape(Yr.T, [T_mm] + list(dims), order='F')\n",
    "print(f\"Memmap: shape={images.shape}, type={type(images).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run evaluate_components to compute per-component metrics.\n",
    "# thresholds are kept low here — actual filtering uses AND logic below.\n",
    "# caiman's built-in uses OR logic (good rval OR good SNR → accept)\n",
    "# which is too permissive for dense data.\n",
    "params = CNMFParams()\n",
    "params.quality.update({\n",
    "    'use_cnn': False,\n",
    "    'min_SNR': 1.0,\n",
    "    'rval_thr': 0.1,\n",
    "    'rval_lowest': -1,\n",
    "    'min_SNR_reject': 0.0,\n",
    "})\n",
    "params.data['decay_time'] = 0.7\n",
    "params.data['fr'] = ops_data.get(\"fr\", 10.0)\n",
    "params.init['gSig'] = (3, 3)\n",
    "\n",
    "print(\"Running evaluate_components...\")\n",
    "est.evaluate_components(images, params, dview=None)\n",
    "\n",
    "print(f\"r_values: median={np.median(est.r_values):.3f}, \"\n",
    "      f\"range=[{est.r_values.min():.3f}, {est.r_values.max():.3f}]\")\n",
    "print(f\"SNR_comp: median={np.median(est.SNR_comp):.3f}, \"\n",
    "      f\"range=[{est.SNR_comp.min():.3f}, {est.SNR_comp.max():.3f}]\")\n",
    "print(f\"CaImAn default (OR logic): {len(est.idx_components)} accepted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Filter and visualize\n",
    "\n",
    "strict AND filtering: a component must pass ALL of:\n",
    "- `r_values >= rval_min` (spatial correlation with movie)\n",
    "- `SNR_comp >= snr_min` (signal-to-noise ratio)\n",
    "- pixel area within `mn_um` to `mx_um` µm diameter (converted via pixel size)\n",
    "\n",
    "adjust thresholds and re-run this cell to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- thresholds (adjust and re-run this cell) ---\n",
    "rval_min = 0.8\n",
    "snr_min = 3.0\n",
    "mn_um, mx_um = 10, 20  # neuron diameter range in µm\n",
    "\n",
    "# convert µm to pixel area\n",
    "dx = meta[\"dx\"]\n",
    "mn_px = np.pi * (mn_um / (2 * dx)) ** 2\n",
    "mx_px = np.pi * (mx_um / (2 * dx)) ** 2\n",
    "\n",
    "# component sizes from sparse A\n",
    "sizes = np.array((A > 0).sum(axis=0)).ravel()\n",
    "\n",
    "good = (\n",
    "    (est.r_values >= rval_min) &\n",
    "    (est.SNR_comp >= snr_min) &\n",
    "    (sizes >= mn_px) &\n",
    "    (sizes <= mx_px)\n",
    ")\n",
    "idx_good = np.where(good)[0]\n",
    "n_pixels = Ly * Lx\n",
    "\n",
    "print(f\"Pixel size: {dx:.2f} µm/px\")\n",
    "print(f\"Size: {mn_um}-{mx_um} µm → {mn_px:.0f}-{mx_px:.0f} px\")\n",
    "print(f\"rval_min={rval_min}, snr_min={snr_min}\")\n",
    "print(f\"\")\n",
    "print(f\"AND filtering: {A.shape[1]} → {len(idx_good)} components\")\n",
    "print(f\"  rval >= {rval_min}: {(est.r_values >= rval_min).sum()}\")\n",
    "print(f\"  SNR  >= {snr_min}:  {(est.SNR_comp >= snr_min).sum()}\")\n",
    "print(f\"  size {mn_px:.0f}-{mx_px:.0f} px: {((sizes >= mn_px) & (sizes <= mx_px)).sum()}\")\n",
    "print(f\"  ALL:         {len(idx_good)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial footprint maps\n",
    "A_good = A[:, idx_good]\n",
    "footprint = np.array(A_good.max(axis=1).todense()).ravel().reshape((Ly, Lx), order=\"F\")\n",
    "comp_ids = np.array(A_good.argmax(axis=1)).ravel().reshape((Ly, Lx), order=\"F\")\n",
    "mask = footprint > 0\n",
    "cell_map = np.where(mask, comp_ids % 20, np.nan)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "axes[0].imshow(footprint, cmap=\"hot\", aspect=\"auto\")\n",
    "axes[0].set_title(f\"max projection — {len(idx_good)} accepted\")\n",
    "axes[0].axis(\"off\")\n",
    "axes[1].imshow(cell_map, cmap=\"tab20\", aspect=\"auto\", interpolation=\"nearest\")\n",
    "axes[1].set_title(f\"cell map — {len(idx_good)} accepted\")\n",
    "axes[1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(f\"Coverage: {mask.sum()} / {n_pixels} pixels ({100*mask.sum()/n_pixels:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric distributions with threshold lines\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "axes[0].hist(est.r_values, bins=100, color=\"gray\", alpha=0.7)\n",
    "axes[0].axvline(rval_min, color=\"r\", ls=\"--\", label=f\"rval_min={rval_min}\")\n",
    "axes[0].set_xlabel(\"r_values\")\n",
    "axes[0].set_title(\"spatial correlation\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].hist(np.clip(est.SNR_comp, 0, 30), bins=100, color=\"gray\", alpha=0.7)\n",
    "axes[1].axvline(snr_min, color=\"r\", ls=\"--\", label=f\"snr_min={snr_min}\")\n",
    "axes[1].set_xlabel(\"SNR_comp\")\n",
    "axes[1].set_title(\"signal-to-noise\")\n",
    "axes[1].legend()\n",
    "\n",
    "axes[2].hist(sizes, bins=100, range=(0, 500), color=\"gray\", alpha=0.7)\n",
    "axes[2].axvline(mn_px, color=\"r\", ls=\"--\", label=f\"{mn_um}µm={mn_px:.0f}px\")\n",
    "axes[2].axvline(mx_px, color=\"r\", ls=\"--\", label=f\"{mx_um}µm={mx_px:.0f}px\")\n",
    "axes[2].set_xlabel(\"size (pixels)\")\n",
    "axes[2].set_title(\"component size\")\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample traces from top accepted components\n",
    "if len(idx_good) > 0:\n",
    "    snr_good = est.SNR_comp[idx_good]\n",
    "    n_show = min(10, len(idx_good))\n",
    "    top_idx = np.argsort(snr_good)[::-1][:n_show]\n",
    "\n",
    "    fig, axes = plt.subplots(n_show, 1, figsize=(14, 2 * n_show), sharex=True)\n",
    "    if n_show == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, ax in enumerate(axes):\n",
    "        ci = top_idx[i]\n",
    "        gi = idx_good[ci]\n",
    "        ax.plot(C[gi], \"k\", linewidth=0.5)\n",
    "        ax.set_ylabel(f\"SNR={snr_good[ci]:.1f}\\nr={est.r_values[gi]:.2f}\", fontsize=8)\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "    axes[-1].set_xlabel(\"Frame\")\n",
    "    fig.suptitle(f\"Top {n_show} accepted components (by SNR)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
